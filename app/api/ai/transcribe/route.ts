import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';

export async function POST(request: NextRequest) {
  try {
    const formData = await request.formData();
    const audioFile = formData.get('file') as File;

    if (!audioFile) {
      return NextResponse.json({ 
        error: 'no_audio_file',
        message: 'No audio file provided'
      }, { status: 400 });
    }

    console.log('üé§ Transcription request received:', audioFile.size, 'bytes', 'type:', audioFile.type);

    // Initialize OpenAI client for OpenRouter
    const apiKey = process.env.NEXT_PUBLIC_OPENROUTER_API_KEY;
    if (!apiKey) {
      console.error('‚ùå OpenRouter API key not found');
      return NextResponse.json({ 
        error: 'api_key_missing',
        message: 'API key not configured'
      }, { status: 500 });
    }

    const openai = new OpenAI({
      baseURL: 'https://openrouter.ai/api/v1',
      apiKey: apiKey,
      defaultHeaders: {
        'HTTP-Referer': 'https://eraiiz.com',
        'X-Title': 'Eraiiz - Voice Agent',
      },
    });

    try {
      // Convert File to ArrayBuffer for OpenAI API
      const arrayBuffer = await audioFile.arrayBuffer();
      const buffer = Buffer.from(arrayBuffer);
      
      // Create a File object that OpenAI can handle
      const file = new File([buffer], 'audio.webm', { type: audioFile.type || 'audio/webm' });
      
      console.log('üìÅ File prepared for OpenAI:', file.size, 'bytes', file.type);
      
      // Use OpenAI Whisper for transcription
      const transcription = await openai.audio.transcriptions.create({
        file: file,
        model: 'whisper-1',
        language: 'en',
        response_format: 'text'
      });

      console.log('üìù Transcription successful:', transcription);

      return NextResponse.json({
        text: transcription,
        success: true
      });

    } catch (apiError: any) {
      console.error('‚ùå Whisper API Error:', apiError);
      console.error('‚ùå Error details:', apiError.response?.data || apiError.message);
      return NextResponse.json({
        error: 'transcription_failed',
        message: apiError.message || 'Transcription failed',
        details: apiError.response?.data || 'No additional details'
      }, { status: 500 });
    }

  } catch (error: any) {
    console.error('‚ùå Transcription processing error:', error);
    return NextResponse.json({
      error: 'processing_error',
      message: error.message || 'Failed to process audio'
    }, { status: 500 });
  }
} 